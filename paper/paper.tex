% !TEX program = xelatex
% Zeitform: Vergangenheit (selten auch Gegenwart)
% uns -> Weglassen wenn es um etwas fachliches geht
% uns -> darf benutzt werden wenn es um die Gruppenarbeit geht
%Requirements:
% 
% 1. Zeitformen anpassen
% 2. Bilder und Referenzen
% 3. Jeder Text fertig
% 4. Progr.-Sprach Konstrukte mit \texttt{String} 
% 5. TODO's raus
% 6. bib.tex file
% 7. citation-standard
% 
% Abstract am 20.6.


\documentclass[paper=a4,fontsize=12pt,twocolumn]{scrreprt}

\usepackage{fontspec}
\usepackage{polyglossia}
\setmainlanguage[babelshorthands=true]{german}

\usepackage[autostyle,german=quotes]{csquotes}
\usepackage[autostyle]{csquotes}

\usepackage[toc,page]{appendix}

\usepackage{array}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{hyperref}
\usepackage{url}
\usepackage{listings}
\usepackage{xcolor}

\usepackage{graphicx}

\usepackage{kantlipsum}

\usepackage[
    backend=biber,
    style=numeric,
    citestyle=authoryear,
]{biblatex}

\addbibresource{./literature.bib}
\graphicspath{ {./images/} }

\usepackage{amsmath}

\title{Project::Foo Abschlussbericht}
\author{Maximilian Bauregger \and Leonard Caanitz \and Lennart Clasmeier \and Patrizio Ferrara \and Luca Müller \and Frederic Voigt}
\date{\today}

\begin{document}

\maketitle

\tableofcontents

\section*{Abstract}

\begin{itemize}
    \item Was wurde wie erreicht?
    \item Wo pflegt sich das in den den aktuellen stand der Forschung ein - wir haben also eine reduzierte ARM Version gebaut
\end{itemize}
\kant[1]


\chapter{Einführung}
Dies ist der Projektbericht zum Projekt Mikroprozessor von Andreas Mäder an der Universität Hamburg. %etw holprig % "Diese Arbeit ist im Rahmen des (oredntlich vorgesehenen )  Projekts ... entsatnden. 
Das Projekt ist dazu angelegt mit einem Team von fünf bis sechs Studierenden einen Mikroprozessor in einer Pipelinearchitektur zu planen, entwerfen, einen Assembler zu schreiben und den Prozessor auf einem FPGA zu synthetisieren.
%war Pipeline nötig? 
Unser Team bestand aus sechs Studierenden - zwei für den Softwareteil, vier für die Hardware.
Die Idee war es eine CPU mit dazugehörigem Assembler und Compiler zu entwerfen um einfache Programme zu schreiben und auszuführen.
Wir orientierten uns hierbei an zeitgenössischen ARM-Prozessoren und deren Befehlssatz (Armv7 ??).
Wir setzten uns als Ziel Fibonacci Zahlen bis zu einer gewissen Iterationsstufe zu berechnen.

In der anfänglichen Planungsphase haben wir die Grundlagen unseres Befehlssatzes und Prozessors besprochen.
Es musste geklärt werden wie lang unsere Befehlsworte sein werden, was für eine Adressmaschine wir verwenden und wie wir Pipelining umsetzen wollen.
Im großen Kreis diskutierten wir die Unterschiede einer Bus-getrieben CPU und einem Pipelineansatz.
Um ein Gefühl für das grobe Konzept eines Pipelining-Prozessors zu bekommen, schrieben wir einen funktionalen Sketch in Python.
Dieser ist im Appendix zu sehen.
Mit diesem ersten Konzept - wobei jede CPU-Stage durch eine Pythonfunktion umgesetzt wurde - war es uns möglich Abhängigkeiten zwischen verschiedenen Komponenten und den Datenfluss selbst besser zu verstehen.
Auf dieses werden wir im Kapitel \enquote{Planungsphase} genauer eingehen.

Der Hardwareteil unserer Gruppe nahm die besprochenen Ansätze und versuchte sich an einer ersten Implementation.
Eine große Hürde stellte VHDL selbst dar.
Keiner aus unserer Gruppe hat bisher mit VHDL gearbeitet.
Wir teilten uns auf um jeder für sich einen kleinen Teil aus dem Python Sketch im VHDL umzusetzen.
Wir entdeckten etliche Testframeworks für VHDL-Komponenten und beschlossen einen Test-Driven-Development Ansatz zu verfolgen und für alle Komponenten zuerst Tests zu schreiben bevor diese implementierte werden.
Hierbei stießen wir auf \texttt{cocotb} - ein in Python geschriebenes Testframework. %Herakless?
Mit diesem war es relativ einfach möglich den gewünschten Output einer VHDL-Komponente - bei gegebenem Input - zu formulieren.
Es wurde \texttt{ghdl} als VHDL Compiler und zur Simulation verwendet.
Unser Komponentengetriebene Ansatz stellte sich letztlich aber als zu komplex heraus.
%Komplex ist nicht das richtige Wort
%% das war auch nicht zu komplex das war eher falsch verstanden, finde gut zu sagen es gab den Umbruch aber doch eher weil wir gelernnt haben das elektr. Bautteil != VHDL kopmponente ist. vllt ehr so in die richhttigung aals wir merh übers synthetissieren gelernt haben
So war das Hardwareteam mitten im Projekt gezwungen die Herangehensweise noch einmal vollständig zu überdenken.
Nach einigen Überlegungen gelangten wir zur Struktur die sich auch in unserem fertigen Produkt abzeichnet.
Hierzu später mehr im Hardwarekapitel.

Auch die Softwareseite durchlief einige Iterationen an Entwicklungsphase.
Am Ende stand ein mit ANTLR / Java geschriebener Assembler-Compiler, welcher in der Lage ist unseren Assembler in Machinencode zu übersetzen.

In der anschließenden Testphase trafen die beiden Teams wieder auf einander.
Es galt das ursprünglich formulierte Ziel der Fibonacci-Zahlenberechnung zu erreichen.
Wärend der Testphase vielen uns noch einige Missverständnisse zwischen Hardware und Software auf.
Zu nennen ist hier zB. die Anzahl der NOOPS, die zwischen abhängigen Befehlen eingefügt werden müssen. 
Am Ende steht ein Prozessor welcher zwar über einen kleinen aber doch vollständigen Befehlssatz verfügt.
% kannst du vollständigkeit beweisen? zu dem absatzt: vlt  erklärenn das wwir zwar pipeliningg haben aber mit no ops arbeiten damit wir nicht fallsche werte pusshen, da gabs dann missverständnis weil die software leute daas anders klonzipiert hatten ?

Moderne Konzepte rund um Sicherheit oder auch generelle Betriebssytemeigenschaften blieben out of scope.
%formulierung -> "out of scope"
Wir haben uns in erster Linie auf eine simple ein-programm-Situation fokussiert.
%Ich würde sagen alles ggroß "Ein-Prograamm_Situation" was meint das nnochmal?
Es ist uns gelungen einen funktionsfähigen Prozessor zu formulieren und einen Compiler für unseren selbst erdachten Assembler zu schreiben.
In der Konklusion werden wir noch Bezug darauf nehmen, welche Erweiterungsmöglichkeiten uns in den Kopf gekommen sind.

% Differenzieren zwischen Erwartungen / "äußeren Zielen" wie "pipelining" und dann inhaltliche ziele.
% "Stages" einführen.
% "Pipelining" erläutern (zmdst. unser Verständnis davon)
% "Hazards" einführen

(Max)

\chapter{Planungsphase}
\label{chap:Planungsphase}

Die Planungsphase beinhaltet die anfänglichen Überlegungen, die daraus resultierenden Diskussionen, sowie die entstandenen Entscheidungen, die die gesamte Gruppe getroffen hatte, bevor sie sich in die Hardware und Software Gruppe aufgeteilt hat.
Angefangen über die gemeinsame erarbeiten des Verständnisses, welche Bestanndteile in einem Prozessor wie arbeiten, über das Skizzieren eines eigenen Prozessors in einem Python \enquote{Pseudocode}, bis zum Erstellen eines Befehlssatzes für diesen Prozessor.

(Paddy)

\section{Planung des Prozessors}
Bevor wir einen Prozessor entwerfen konnten mussten wir zunächst unser Wissen über die Funktionsweise von Prozessoren auffrischen und die Wissensstände innerhalb der Gruppe angleichen. Dazu bedienten wir uns des angebotenen Materials, aus der RS Vorlesung. Anschließend entwarf die Gruppe gemeinsam eine erste Skizze eines Prozessors ohne Pipelining, um das eigene Wissen zu überprüfen.
Im Anschluss daran widmeten wir uns der eigentlichen Pipelining Architektur, indem wir die Skizze Abbildung??? zurate zogen.

%Um die Datenströme innerhalb des Prozessors und die Abhängigkeiten zwischen den einzelnen Komponenten besser nachvollziehen zu können, schrieben wir außerdem einen Entwurf in Python. In diesem Entwurf leiteten wir Funktionen von den fünf \textt{stages} aus der Skizze ab.


% Schöne Einleitung fehlt? Paddi
% Beim Entwerfen eines Prozessors, musste die Projektgruppe das theoretisches Wissen über die Funktionsweise des Prozessors auffrischen, da diese teilweise in Vergessenheit geraten ist.
% Dabei wurden Unterlagen aus vergangenen Vorlesungen, sowie für das Projekt zur Verfügung gestellte Materialien genutzt.
% Nachdem sich jedes Projektmitglied mit der theoretischen Funktionsweise befasst hatte, wurde gemeinsam eine Skizze entworfen, die einzelne Bestandteile des Prozessors und deren Datenströme visuell festhielt.
% Dies diente als Bestätigung für das theoretische Verständnis, sowie als erste Vorlage für den zu realisierenden Prozessor.

\begin{figure}[h]
\centering
% \includegraphics{Figure 3.2.1}
\caption{Komponenten und Datenströme}
\end{figure}

Durch diese Skizze hatte die Projektgruppe ein gemeinsames Grundwissen erarbeitet, sodass jede Person in der Gruppe eine Vorstellung hatte, wie der Prozessor aussehen könnte.

Problematisch war, dass der Prozessor, der daraus entstanden ist, ein Bus-System besitzt, was den Projektanforderungen nicht gerecht wurde.
Um diesen Prozessor mit Bus-System in einem Prozessor mit Pipeline-Architektur umzuwandeln, musste in Erfahrung gebracht werden, wie ein Pipeline-Architektur aussehen kann.
In den bearbeiteten Unterlagen, befindet sich eine Vorlage für ein Pipeline-Prozessor mit 5 \textit{Stages}.

\begin{figure}
    \centering
    \includegraphics[scale= 0.4]{proc_skiz.png}
    \caption{Caption}
    \label{fig:my_label}
\end{figure}

Nach Definition ist eine Stage, eine Teilaufgabe eines ganzen Befehls des Prozessors.
%citation needed
Diese Teilaufgaben sollen unabhängig voneinander arbeiten können.
In dieser Vorlage wird der ganze Befehl in 5 Teilaufgaben unterteilt, sodass 5 Stages entstehen.
Die 5 Stages sind Fetch, Instruction Decode, Execute, Memory Access und das Write Back.
Deren genaue Arbeitsweise wird im Kapitel 3.2 beschrieben.
% ????????? Paddi
Diese Unterteilung wird in einem Prozessor durch Pipeline-Register dargestellt.
Um einen Pipelining Prozessor zu bauen haben wir die einzelnen Komponenten des Prozessors in Stages unterteilt, die dann mithilfe von Pipelining Registern voneinander abgetrennt wurden.
%Diese Register sind zwischen den Komponenten des Prozessors geschaltet und dienen als Anfang bzw. Ende einer Stage.
Alle Informationen die sonst an andere Komponenten weitergegeben worden wären, werden hier zwischengespeichert.

Der Vorteil einer Unterteilung in Stages ist, dass der Prozessor, unabhängige Befehle gleichzeitig bearbeite kann.
Dies erreicht er, indem er einen Befehl, in einem Prozessor-Takt, eine Stage \enquote{weiter schiebt}.
Das bedeutet, dass die Daten von einem Pipeline-Register von den nachkommenden Komponenten verarbeitet werden und das Ergebnis in das nächste Pipeline-Register geschrieben wird. 
Da in den Stages unabhängig voneinander gearbeitet werde kann, können so in einem Prozessor mit 5 Stages, bis zu 5 Befehle gleichzeitig bearbeitet werden. 
Diese Befehle befinden sich dann jeweils in unterschiedlichen Stages des Prozessors, bzw. in den jeweiligen Pipeline-Register zwischengespeichert.
Somit kann der Durchsatz an Befehlen des Prozessors im Optimalfall wesentlich erhöht werden.

Für den zu entwickelnden Prozessor wurde sich auch für eine Pipeline-Architektur mit 5 Stages entschieden, da eine Vorlage schon existierte und uns dies sinnvoll erschien.
% "und uns dies sinnvoll erschien" -> Formulierung ersetzen
Da einige Gruppenmitglieder mit Python vertraut sind und das Wissen über VHDL mangelte, kam die Idee auf, einen groben Sketch in Python zu schreiben.
Aufbauend auf der Abbildung aus dem Foliensatz, wurden für die jeweiligen Stages des Prozessors jeweils eine Funktion in Python gewidmet. % todo gewidmet ersetzen
Die Parameter der Funktionen sind die Inputs der jeweiligen stage und die Returnwerte sind eine Liste der Stage-Outputs.
So war es möglich einen groben Überblick über alle benötigen Komponenten und ihre Abhängigkeiten zu gewinnen.

----------------------------------------------

Nachdem eine 1 zu 1 Umsetzung von dem Pythonsketch in VHDL durch mangelnde VHDL Kenntnis nicht möglich war, wurde die Logik der Komponenten ausgelagert.


(Paddy)

\section{Wortlänge und Adressmaschine}


Bei der Adressmaschine wurde sich für eine 3 Adressmaschine entschieden.
Die 0- oder 1- Adressmaschine wurde direkt ausgeschlossen, da diese zu umständlich und nicht zielführend gewesen wären.
Die 3-Adress Maschine hat zwar keine funktionalen Vorteile, gegenüber der 2-Adressmaschine, aber der Aufwand, komplexere Abläufe zu realisieren ist geringer.
Ein „add“-Befehl kann sein Ergebnis beispielsweise direkt an eine dritte Adresse schreiben und ist somit in einem Befehl realisierbar.
So werden umständliche Kopiervorgänge gespart.
Zur Fehlerfreien durchführung der Kopiervorgänge (Vermeidung von Hazards) in einer 2-Adressmaschine wäre eine große Anzahl an NOOps notwendig, die mithilfe einer 3-Adressmaschiene eingespart werden können.
Eine 3-Adressmaschine ist sowohl schneller, als auch einfacher in der Handhabung.

Bei der Bit-Zahl wurde sich für 32 entschieden.
32 Bit Wortlänge reicht für alle Befehle und werden nie ganz ausgeschöpft.
Darum wäre auch eine längere Bitzahl überflüssig gewesen.

% grobe struktur:
% Beispiele! Konkret machen
% Bitzahl wirklich "irrelevant"?
% Wortlänge ergibt sich aus der 3-adressmaschine

(freddy)

\section{ 32-Bit-Code und seine Struktur}

In den folgenden Kapitel wird die Struktur des 32-Bit-Codes behandelt.
Es wird beschrieben wie der Code Unterteilt wurde und welche Denkprozesse dabei durchlaufen worden sind.
Angefangen von der Unterteilung der Bits, über die Auswahl des Befehlssatzes und des daraus resultierenden Opcodes bis hin zu den Spezialfällen die aus den vorherige Entscheidungen heraus entstanden sind.

Bei den Überlegungen wie die Struktur des Codes aussehen soll kamen die folgenden Ergebnisse: 
\begin{itemize}
    \item Die ersten Bits stehen für den Opcode.
    Die Länge wurde in Abhängigkeit an der Anzahl der Befehle auf 5 Bits gewählt.
    Diese ermöglichen das ergänzen weiterer Befehle da nicht alle Opcodes zugewiesen sind. 
    \item Das darauf folgende Bit signalisiert ob es sich beim letzten Operanden um ein Immediate-Wert handelt.
    Näheres wird im Kapitel Immediate-Bit erläutert.
    \item Die restlichen Bits sind für die Operanden reserviert.
    Dabei wurde sich auf einen 16-Bit langen Immediate-Wert geeinigt.
    Dieser erleichtert für die  Softwareprogrammierung das Darstellen größerer Zahlen (bis zu 32-Bit) mit insgesamt 3 Befehlen (Zuweisung in ein Register der ersten 16 Bits, 16 Shift des Registers, Zuweisung der letzten 16 Bits in das Register über einen XOR Befehl).
    Durch die 5 Bits des Opcodes, 1 Bit des Immediete-Bits und 16-Bits des möglichen Immediatewertes, können aus Platzgründen nur noch 5 Bits für die Register zugewiesen werden.
    Dies ergibt eine Gesamtzahl von 32-Registern.
\end{itemize}

\begin{figure}[h]
\centering
% \includegraphics{Figure 3.2.1}
\caption{Bild der Struktur}
\end{figure}

Nachdem die Struktur festgelegt worden ist, musste sich auf ein Befehlssatz geeinigt werden.

\section{Befehlssatz und seine Zuweisung}

Um einen Überblick über mögliche Befehlssätze zu bekommen, wurde sich an dem ARM Befehlssatz orientiert\footnotemark.
\footnotetext{//(*link zum ARM Befehlssatz)//}
Dieser wurde noch reduziert, da nicht alle Befehle für das Projekt relevant sind.
Bei der Reduzierung wurden die Befehle in 3 Kategorien unterteilt:
\begin{itemize}
    \item \enquote{must-have}:
    Das Minimum das nach Erachtens der Gruppe der Prozessor haben muss um die gestellten Anforderungen zu erfüllen. In diesem konkreten Fall, alle Funktionen die benötigt werden um eine Fibonacci-Folge zu berechnen. (z.B. Zuweisungen, Addieren, Sprünge) 
    \item \enquote{nice-to-have}:
    Funktionen die bei übrig gebliebener Zeit implementiert werden können.(z.B. Multiplizieren)
    \item \enquote{irrelevant}:
    Zu komplexe oder für das Projekt irrelevante Funktionen.
\end{itemize}
Für den vorläufigen Befehlssatzes wurde sich zunächst auf die \enquote{must-have} Befehle fokussiert.
Der somit entstandene Befehlssatz musste nun einem Opcode zugewiesen werden.
Die ausgewählten Befehle wurden in 3 Kategorien unterteilt, die sich in der Anzahl der angegebenen Parameter unterscheiden.
Um diese Unterscheidung auch im Opcode erkenntlich zu zeigen, haben alle 3 Kategorien (ONEOP, TWOOP, THREEOP) unterschiedliche erste 2 Bits in ihrem Opcode.
Sodass eine konsistente Regel ihrer Layout erstellt werden kann.

\begin{figure}[h]
\centering
% \includegraphics{Figure 3.2.1}
\caption{Bild der mögliche Layouts}
\end{figure}

Dies dient vor allem der Übersicht sowie einer einfacheren Decodierung, wie im Kapitel Decoder beschriebe ist. 
Ein Diskussionnspunkt bei der Zuweisungen war, ob ein Opcode bei unterschiedlichen Typen von Parametern(Immediate-Wert bzw. Register) nicht gleich ist.
Dies hätte zur Folge, dass bei Befehlen, die einen Immediate-Wert zulassen, ein eigener Befehl erstellt werden müsste.
Wie z.B bei einer Addition; das \texttt{ADD} müsste mit einem \texttt{ADDI} (Addition mit einem Immediate)  ergänzt werden.
Eine andere Möglichkeit ist die Unterscheidung nicht im Opcode stattfinden zu lassen, sondern diese auszulagern.

\section{Immediate-Bit}

Das Immediate-Bit ist eine mögliche Lösung um diese Auslagerung zu realisieren.
In diesem speziellen Fall wäre das ein Bit das sich nach dem Opcode befindet.
Es ist \enquote{0}, wenn es sich in de Zuweisungen nur um Register handelt und \enquote{1}, wenn eine Zuweisung ein Immediate-Wert ist.
Somit wird auch schon im 32-Bit-Code ersichtlich, welche Typen von Parameter zugewiesen werden.
Eine Auslagerung und das Hinzufügen eines zusätzlichen Befehls im Befehlssatzes würden bei diesem Projekt schlussendlich zum selben 32-Bit-Code führen.
Vorteile einer Auslagerung ist die geringere Anzahl an Befehlen die benötigt werden.
Dadurch wird die Softwareprogrammierung vereinfacht, da sie zwischen einer direkten und indirekten Zuweisung nicht unterscheiden muss.
Aus diesen Gründen wurde beschlossen, die Unterscheidung nicht im Opcode zu behandel, sondern ein Bit in der 32-Bit-Anweisung als \enquote{Immediate-Bit} zu deklariert.


\subsection{Diskussion bei Befehlen}

Bei der Überlegung über das Immediate-Bit kam es bei der Zuweisungen der Befehle Diskussionen.
Betroffen waren folgende Befehle: der \enquote{Jump}-Befehl, der \enquote{Branch}-Befehl der \enquote{Store}-Befehl und der \enquote{Load}-Befehl. 
Bei der Diskussion ging es primär um die Frage, ob relative Zuweisungen möglich sein sollen.
Das heißt in diesen speziellen Fällen, ob z.B. relative Sprünge zu realisieren sind.
Relative Sprünge sind Sprünge, die relativ zur Zieladresse sind.
Diese relativen Zuweisungen ermöglichen das Erstellen gewisser Konstrukte, wie Arrays.
Hier müsste nur in einem Register hinterlegt werden, an welcher Speicheradresse das Array anfängt.
Mit dieser Information kann auf einer beliebige Stelle des Arrays zugegriffen werden, obwohl die genau Speicheradresse nicht bekannt sein muss, da die Anfangsadresse des Arrays vorhanden ist.
Ein Argument gegen eine relative Adressierung ist, dass alle Adressen dem Projektteam bekannt sind.
Bei kleineren Programmen kann der Entwickler die Adressen, da sie ihm alle bekannt sind, \enquote{hardcoden}.
Da aber bei größeren Programmen, bzw. auch bei mehreren Programmen die gleichzeitig laufen, eine  \enquote{hardcodierung} durch die erhöhte Komplexität der Programme fast unmöglich ist, wurde sich für eine indirekte Adressierung entschieden.
% reword?
Die 4 Befehle \enquote{Jump}, \enquote{Store}, \enquote{Branch} und \enquote{Load} wurden somit als Befehle mit 3 Operanten angelegt um relative Zuweisungen zu ermöglichen.


(paddy)

\chapter{Hardware}

%Dieses Kapitel behandelt die Umsetzung unseres Entwurfs in VHDL-Code.
%Dazu gehörte sich mit der Sprache an sich vertraut zu machen, sich auf ein Abstraktionsniveau zu einigen und die Implementationsdetails festzulegen.
%Da die Auseinandersetzung darüber als eine Entwicklung über dass gesamte Projekt betrachtet werden kann, hielten wir es für angebracht diesem Prozess in einem eigenen Kapitel über das Vorgehen Rechnung zu tragen.
%In diesem werden Arbeitsteilung und Gedankengänge ausgeführt. %???
%Anschließend wird unser Ergebnis detailliert vorgestellt, die Komponenten und ihre Funktionen besprochen. Dazu gehören die Implementierung der fünf Stages. %Dieses Kapitel ist Müll

Dieses Kapitel behandelt die Umsetzung unseres Entwurfs in VHDL-Code. Hier wird der Entwicklungsprozess und der endgültige Entwurf vorgestellt. Rückblickend betrachtet hat die Auseinandersetzung mit der Funktionsweise von VHDL den Großteil der Zeit in Anspruch genommen. Die Erkenntnisse über Syntax, Semantik vor allem aber über das geforderte Abstraktionsniveau - wenn man so will die gedankliche Synthese unseres Entwurfs die zu lauffähigen VHDL Code führen sollte verlief eher Schrittweise. Diesem Prozesses wollen wir in einem eigenen Kapitel [REF KAP 3.1] Rechnung tragen. Anschließend wird unser Prozessor detailliert vorgestellt und das Verhalten besprochen. "Feztch rausgefallen nochmal ausbreiten das in diesem teil deutlcih wird wie entwurf und lösung auseioanderfallen
" Im folgenden sprachliche Konstrukte aus VHDL in Englisch bezeichnet, im Gegensatz zu      


Den Großteil der Zeit hat die gedankliche  
%sagen wenn english gesprochen wird dann meint es vhdl konstrukte wenn deutsch dann meinen wir daasa wwas wir saaaggenn : basp Compnennts udn Komponnenten

%beim ersten mal entity VHDL-Entity saagen udn dann in italic um klar zu amchen ah neuer begriff genaausso bei architecture

% nochmal stärken wwarum es hier so ein explizit historisches kapitel gibt

(luca)

\section{Von der Skizze zum Entwurf}

An dieser Stelle soll das Vorgehen des Hardware-Teams vorgestellt werden.
Dabei sollen weniger technischen Implementationsdetails diskutiert werden, sondern die Arbeit der Gruppe von der ersten Skizze bis zum endgültigen Ergebnis umrissen werden.
Im Fokus stehen die Herangehensweise, Fehleinschätzungen und der Prozess des Erkenntnisgewinns.
Zeitlich betrachtet beschreibt dieses Kapitel die Arbeit des Hardwareteams im Anschluss an die gemeinsame Planungsphase.
Auf dem Papier ist bereits an diesem Punkt eine Skizze des Prozessor und ein entsprechender Python Pseudocode entstanden (siehe Anhang).
In Verbindung mit der Skizze aus der Vorlesung \footnote{Rechnerarchitektur: ISA / Pipelining / Speicherhierarchie - Foliensatz Folie 119} musste dann nur der Python Code in funktionierenden VHDL Code umgewandelt werden.

\begin{figure}
    \centering
    \includegraphics[scale= 0.4]{proc_skiz.png}
    \caption{Caption}
    \label{fig:my_label}
\end{figure}


Das Hardware Team hat sich intern darauf geeinigt einmal pro Woche gemeinsam an dem Projekt zu arbeiten. 
Hier wurden selbst erarbeitete Lösungen und Probleme diskutiert, die Arbeit aufgeteilt und das weitere Vorgehen besprochen.
Da von uns niemand Erfahrung in Hardware-Beschreibungssprachen hatte, mussten sich zunächst dass ganze Team mit VHDL Auseinandersetzen.
Gleichzeitig sollte die Zeit Komponente nicht außer acht gelassen werden.
Die Bestrebung war ein System zu Entwickeln von dem wir uns versprachen das Projekt technisch und inhaltlich voran zu treiben.
%klar machen dass es um die didaktische ebene geht.
Dazu haben wir uns auf ein "Drei-Phasen-Programm" geeinigt. In der ersten Phase haben sich alle Teammitglieder individuell mit VHDL beschäftigt.
Vielversprechendes Material wurde im GitLab gesammelt.
Darüber hinaus wurden Schwerpunkte vergeben zu denen unter anderem Entities, Architectures, Prozesse und mögliche Umsetzungen von Pipelining gehörten.
Für uns lag nach den ersten Recherchen nahe für jede Komponente aus der Skizze bzw. dem Python-Sketch eine entsprechende VHDL-Komponente zu schreiben.
%(wie in abbildung sowieso zu sehhen) 
Der Gedanke lässt sich in etwa so zusammenfassen: Jedes elektrische Bauteil - wie ALU und der Decoder sollte eine Entsprechung als Entity mit zugehöriger Architecture erhalten.
Die in den Entities definierten Schnittstellen sollten die Kommunikation der einzelnen Stages untereinander gewährleisten, während die jeweilige Architectures die gewünschte Datenverarbeitung übernähme.
In der zweiten Phase wurden die Stages aufgeteilt, sodass jeder mindestens eine Komponente in VHDL programmiert hätte.
Das Ziel war einen Gerüst zu konstruieren an dem jeder individuell mit der eigenen Komponente anknüpfen konnte und gemeinsam nach Absprache iterativ weiter gearbeitet werden konnte.
In der dritten Phase würden dann die individuell erstellten Komponenten - so unsere Vorstellung - nach dem Baukastenprinzip zusammengesetzt und so lange verbessert werden bis ein lauffähiger Prototyp entstehen würde.
Bei diesem Prozess haben wir zunächst noch einmal von unserem Entwurf abstrahiert und in der Umsetzung reduziert.
Das bedeutet, dass die Implementierung von Speicher und Pipeline-Registern zunächst auf einen späteren Zeitpunkt verschoben wurde.
Der Fokus lag darauf lauffähigen VHDL-Code zu produzieren.
Die so erstellten Teilkomponenten sollten im Sinne von Unit-Tests mit CocoTb \footnote{https://docs.cocotb.org/en/stable/ 24.05.2021} getestet werden.
Unsere Methode führte insofern zum Erfolg, als dass alle Teammitglieder theoretische und praktische Grundlagen in VHDL erwarben.
Dadurch waren alle in der Lage sich an Diskussionen zu beteiligen.
Durch die individuelle Spezialisierung konnten wir uns gegenseitig Hilfestellung leisten und es fielen Probleme auf, die andern zunächst verborgen blieben.
%Vielleicht funktional im sinne funktionaler Programmierung _ Wasa ist dennnn funktionnal ggenau? mach das mal deutlicher
Es zeigte sich, dass wir insgesamt zu Funktional über die Implementierung nachgedacht haben.
Das lag zum Einem daran, dass unsere eigene abstrakte Vorstellung eines Prozessors sich zu stark an der Skizze und dem Pythoncode orientierte.
Zum Anderen daran, dass uns das von VHDL geforderte Abstraktionsniveau und die Synthese nicht klar waren.
Der entscheidende Wendepunkt kam bei der Implementierung des \texttt{sgn\_ext}.
Dieser war nach unserem Baukastensystem Ansatz eigene Entity mit entsprechender Architecture konzipiert worden.
Ein Beratungsgespräch mit Andreas legte es nahe, dass \texttt{sgn\_ext} schlicht als Prozess zu implementieren.
Auch die von uns zuvor strikt als notwendig begriffenen Entities und Architectures eher als eine Abtraktionshillfe für den Programmierer zu betrachten als eine Notwendigkeit für die Synthese.
%Beratunngsgsespräch ddrinnn lasssen andreass raus
Genauer, die in der Architecture angestoßene Verarbeitung von Signalen sind auch einfach nur Prozesse.
Die wichtigsten Erkenntnisse die daraus resultierten waren: Prozesse in VHDL laufen parallel ab, die Abarbeitung innerhalb eines Prozesses aber sequenziell.
Signale, die wir zuvor eher als Variablen betrachtet haben enthalten konstant Werte und können somit - bildlich gesprochen - eher als elektrische Leitungen betrachtet werden auf denen dann Werte anliegen, die nach bedarf beschrieben und ausgelesen werden können.
Die richtige Handhabung von Signalen führte immer wieder zu Problemen durch gleichzeitige Lese- und Schreibzugriffe.
Diese produzierten undefinierte Werte bzw. wurden zu früh überschrieben und setzten so falsche Inputs für die Verarbeitungen die auf das gleiche Signal angewiesen waren.
Um den Zugriff auf Signale zu steuern, machten wir die Eingangssignale für unserer Entities von der Clock abhängig und fanden damit auch letztendlich eine Implementation für Pipelining.
% nicht die inputs für entities, so haaben wwir raaussgefundenn so geht nen register und dann haben aufgehört zu versuchen pipeline register entity zu schreiben udn dann haben wir das alles über signale in cpu gemacht.
Auf Grundlage des neu erworbenen Wissens haben wir den oben beschriebenen Baukasten-Ansatz verworfen und ein neues System entwickelt. 
Der Entwurf hat nunmehr drei Entities: Die CPU als Kernstück des Prozessors.
Hier finden nun alle Stages ihre Entsprechung als Prozess, außerdem werden alle zugehöriegen Input- und Outputsignale definiert.
Die ALU mit einem Switch-Statement für die logischen und arithmetischen Operationen.
Abschließend der Decoder um die Befehlsworte aufzuschlüsseln und für die weitere Bearbeitung zu präparieren.
Im folgenden Kapitel wird die technische Umsetzung des letztendlichen Entwurfs detailliert vorgestellt.

(luca)
%Titel vielleicht: Der Aufbau des Prozessors 
\section{Struktur oder Setup oder wie das aussieht}
Struktur und Kommunikation -
% Zusammenhänge von componenten
% Wie fließen daten durch den prozessor
% componenten, entities, architectures - vhdl setup
%Datentypen
%Packages und Components - Subtypen

%mpure muss in architectture kann aber auf werte außerhalb der funkttion zugreifen solnag sie in der architectue ssind

Die CPU ist in fünf \textit{Stages} unterteilt.
Die Befehle \enquote{fließen} durch diese Stages hindurch.
Jede dieser Stages besitzt Input- und Outputsignale.
Die Inputsignale einer jeden Stage werden \textit{clocked} beschrieben.
Sie werden somit als Register synthetisiert.
Der Prozess, der dies veranlasst, besitzt das Suffix \texttt{\_pipeline}.
Die Outputs einer jeden Stage sind nicht geclocked und somit nur \enquote{einfache} Datenleitungen.
%etwas abgehackt

%vlt das mit der fetch stagesim opener erwähnen 
\begin{description}
  \item[Fetch]
  Die Fetch Stage ist recht simpel.
  In ihr wird die Input Instruction clocked gelesen und auf den Output gelegt.
  % TODO really? it seems like, its outputs are never used.
  % TODO remove fetch
  \item[Instruction Decode]
  Im Instruction Decode wird der gelesene Befehl dem Decoder präsentiert und die Outputs des Decoders genutzt um entsprechende Register und Flags zu lesen.
  \item[Execute]
  Die Execute Stage legt entsprechende Signale an die ALU-Komponente an und gibt das Resultat aus.
  \item[Memory Access]
  Hier passieren zwei verschiedene Dinge.
  Zum Einen wird entschieden, ob gesprungen wird oder nicht.
  Dies wird als Outputsignal der nächsten Stage präsentiert.
  Zum Anderen wird das \texttt{data\_addr} Signal entsprechend geschaltet, sofern der Opcode ein \texttt{STR} oder \texttt{LDR} ist, und Daten geschrieben bzw. gelesen werden.
  \item[Write Back]
  Im Write Back passieren wiederum zwei Dinge parallel.
  Auf Basis des \texttt{will\_jump} Signals wird entweder der Program Counter (PC) um eins erhöht oder auf das Resultat der Memory Access Stage gesetzt.
  Sofern der bearbeitete Befehl in ein Register schreiben soll, wird dies ebenfalls getan.
\end{description}

\subsection{Setup}

Die CPU ist in drei VHDL Entities unterteilt: Die \texttt{cpu} selbst, die \texttt{alu} und der \texttt{decoder}.
Die gesamte Pipelinelogik ist in der \texttt{cpu} Entity untergebracht.
Sie besitzt nach außen Adress- und Datenleitungen für die Anbindung der Speicher\footnotemark und einen \texttt{clk} Input.
\footnotetext{Unser Design geht von zwei getrennten Speichern für Daten und Instruktionen aus.}
Die dazugehörige Architektur \texttt{cpu\_arc} nutzt die \texttt{decoder} und \texttt{alu} Komponenten intern.
Es wird außerdem ein \texttt{cpu\_pkg} bereitgestellt, dass die \texttt{cpu} Komponente und oft verwendete Typen enthält.

Die \texttt{alu} Entity ist recht simpel gehalten.
Sie nimmt eine \enquote{Rechenaufgabe} mit zwei Operanden entgegen und gibt das Ergebnis sowie eventuelle Flags nach außen.
Da die ALU keinen internen Zustand hat, besitzt sie auch kein \texttt{clk} Signal.
Neben der \texttt{alu} Entity selbst beinhaltet das \texttt{alu\_pkg} die speziellen ALU Opcodes und die \texttt{alu} Component.

Der Decoder ist ähnlich zur ALU gehalten.
Die \texttt{decoder} Entity erhält nur eine Instruktion als Input.
Sie ist ebenso nicht \texttt{clk}-abhängig.
Die Outputs des Decoders bestimmen, welche Operation die ALU ausführt und welche Register gelesen werden.
Im \texttt{decoder\_pkg} sind die \texttt{decoder} Component und alle Opcodes definiert.

% Component begriff erläutern? (Am besten vorher)

(max)

\section{Input / Output}

Die CPU benötigt natürlich noch Speicher für Daten und Instruktionen um ein Programm ausführen zu können.
% Colloquial? "naturlich noch" weg? außerdem?
Dieser wird in der \texttt{processor} Entity mit der CPU verbunden.
Es wurde die \texttt{sram2} Entity, welche uns von Andreas Mäder\footnotemark zur Verfügung gestellt worden ist, verwendet.
\footnotetext{Guter Mann. Kudos dafür! *bussy* und Herzchen}
% nicht vergessen!
Im \texttt{processor} werden zwei Instanzen dieses Speichers erzeugt - eine für Daten, eine für Instruktionen.
Der Adress-Input dieser Speicher ist mit den jeweiligen Adress-Outputs der CPU verbunden.
Da die Speicher nicht mit vollen 32 bit Adressen operieren, werden die Output-Adressen der CPU \enquote{beschnitten}.
Es ist somit nicht möglich den vollen 32 bit Adressraum zu nutzen.
So wird aber nicht der gesamte 32 bit Raum beim simulieren alloziert.

Des weiteren stellt der \texttt{processor} ein \texttt{clk} Signal für Speicher und CPU bereit.

(max)

\section{Register}

Neben vielen internen Registern, wie zB. den Pipelineregistern bestitzt die CPU 32 \enquote{Datenregister}.
Diese können von laufenden Programmen ausgelesen und meist auch beschrieben werden, um zB. Rechenergebnisse zwischenzuspeichern, ohne in den Speicher schreiben zu müssen. 
Diese sind mit fünfbit ($2^5 = 32$) Adressen zugreifbar. 
Einige dieser Register dienen einen speziellen Zweck - sogenannte \enquote{Special purpose} Register - und unterliegen gewissen Restriktionen.
\begin{description}
    \item[Zero]
        Das Zero Register R0 hat immer den Wert $0$.
        Es ist in dem Sinne kein Register sondern 32 dauerhaft auf 0 gezogene Bits und daher auch nicht beschreibbar.
        % vllt umformulieren?
    \item[Flags]
        Um Flags wie compare, overflow und carry zu speichern, wird das erste Register R1 verwendet.
        Berechnet die ALU eine Operation, welche eine Änderung der Flags zur Folge haben könnte (COMPEQ, COMPGT, ADD, ADC, SUB, SBC), wird das entsprechende Bit in der Write Back stage im Flags register gesetzt.
        Das Register ist frei beschreibbar.
    \item[Link]
        Im Falle eines Sprunges, wird der aktuelle PC wert in das link Register geschrieben.
        Dies ermöglicht es, wenn zu einer Subroutine gesprungen wurde, wieder zum ursprünglichen Programm zurückzukehren.
        Das Register verhält sich sonst wie ein generisches Datenregister.
        Es ist vor allem Aufgabe des Programmes, sofern zu einer weiteren Subroutine gesprungen werden soll, sicherzustellen, dass der Zustand des ursprünglichen Link-Registers nicht verloren geht.
    \item[PC]
        Das PC Register gehört - ähnlich zum Zero-Register - in dem Sinne nicht zu den anderen dem Programm zugänglichen Registern.
        Es ist nicht in der Registerbank verortet sondern steht für sich.
        Der \texttt{instr\_addr} Ausgang der CPU ist fest mit dem PC Register verbunden.
        Um Programmen das Auslesen des PC Registers zu ermöglichen, ist es als R31 addressierbar. Schreiboperation werden jedoch ignoriert.
        Hierfür muss dediziert der \texttt{JMP} Befehl verwendet werden.
\end{description}

% italic schreibweise für Begriffe (z.B. verschiedene flags)

Die Implementation der Datenregister stellte uns vor einige Schwierigkeiten.
Uns war nicht bewusst wie genau ein Register in VDHL zu formulieren war.
Der erste Ansatz eine eigene Entity pro Register zu schaffen wurde schnell verworfen.
Als uns klar wurde, dass Register letztlich nur \enquote{geclockt} beschriebene Signale sind, schufen wir die Registerbank - letztlich nur ein Array mit 32 Feldern vom  Typ \texttt{std\_logic\_vector} mit einer Länge von 32 bit.
Zugriffe auf diese Datenstruktur führten immer wieder zu undefinierten Werten.
Wie uns später klar wurde ist es keine gute Idee konstante Werte an Register anzulegen oder zeitgleich zum gleichen Zeitpunkt zweifach in das Register zu schreiben.
Die Lösung lag darin, alle Schreibzugriffe in einem Prozess im Writeback - \texttt{wback\_pipeline} - abzuhandeln.
Das PC Register wurde in dem Zuge auch aus der Registerbank ausgelößt. 
Es wird nun durch den - und nur den - \texttt{wback\_pc\_set} Prozess im Writeback beschrieben. %einzig und allein?

(max)

\section{PC Handling und Sprünge}
%zeiten grammatik ändern
Um den richtigen Befehl aus dem Instruction-Speicher zu laden wird ein Register namens Programm Counter (PC) verwendet, indem die aktuelle Adresse steht.
Der PC wird in der fetch-stage verwendet um Befehle aus dem Speicher laden zu können.
Der PC muss in jedem Clock Zyklus um Eins inkrementiert werden, um bei der nächsten fetch-stage Ausführung den nächsten Befehl anzuvisieren. 

Die ursprüngliche Implementation hatte in jeder Pipelinestage einen next-sequence PC Wert gespeichert, der den PC Wert enthielt der gesetzt sein soll, sobald der indizierte Befehl abgearbeitet werden soll.
Dieser wurde in der fetch-stage berechnet und in der write-back stage genutzt,um die Speicheradressen zu setzten. 
Der next-sequence PC wurde aufgegeben, da es einige Schwierigkeiten gab:
%Ab hier passt was nicht mit den Zeiten
Die erste Implementation war fehlerhaft.
Das Durchlaufen eines Befehls durch die Pipeline dauert vier schritte.
Der next-sequence PC wurde aber nur um eins erhöht.
Wenn dieser Befehl im memory access landet und genutzt wird um die Instruktionsspeicheradresse zu setzten, sind schon vier Zyklen vergangen, seitdem in der fetch-stage der next-sequence Pc gesetzt ist.

Eine weitere Schwierigkeit ergibt sich aus den fehlenden Initial-Zuständen.
Jede Komponente, inklusive des next sequence PC ist undefiniert, bei Simulationsstart.
Auch in der Realität kann nicht angenommen werden, dass alle Werte auf 0 gesetzt sind.
Dies führt insbesondere beim next-sequence PC Handling zu Schwierigkeiten, da in jedem Clock Zyklus der Wert im next-sequence PC im memory access als Adresse genutzt wird.
Ist dieser undefiniert, erhält das Instructions-memory einen undefinierten Wert.
Weiterhin muss darauf geachtet werden, wie die richtigen Initialwerte gesetzt sind:
Wäre alles mit 0 initialisiert, würde vier mal der nullte Befehl geladen werden.
Der erste Befehl wird auf 1 gesetzt und die anderen drei werden wieder mit 0 geladen. Die fetch-stage nimmt sich weiterhin den nächsten Befehl.

%Bild reinpacken

Die Jumps haben zu weiteren Problem geführt.
Die Motivation zur Implementation des next-sequence Pcs war die Vermutung, dass Sprünge damit einfach realisierbar gewesen wären.
Ein Befehl trägt, beim Durchlauf durch die Pipelinestages, den Wert des PCs mit sich.
Diesen Wert umschreiben, wenn er ein Sprung ist, schien zunächst einfach.
So mit wäre eine externe Sprung Logik nicht nötig. 

Angenommen ein Jump-befehl läuft durch die  Pipeline.
Der next-sequence PC liegt bei dem aktuellen Pc Wert plus 4, sobald dieser Befehl in der fetch-stage ist.
Läuft dieser Jump-befehl jetzt weiter und kommt in der memory-access stage an, ändert diese den next-sequence PC Wert auf die Sprungadresse.
Das sorgt dafür, dass der nächste Befehl, den die fetch-stage laden wird, der ist, auf den gesprungen wird.
Die problematik gibt sich nun aber daraus, dass der Befehl direkt nach dem Jump (der eine Stufe weietr oben liegt) von dem Sprung verhalten nicht geändert wird.
Einen Prozessortakt weiter und der nachfolgende Befehl im memory-acess landet, ist der next-sequence Pc von diesem Befehl nicht vom Sprung berührt und wird direkt wieder für den Instrction-Speicher verwendet.
In der fetch-stage wird der nächste Befehl mit diesem PC Wert geladen.
Das Ganze ist offensichtlich fehlerhaft und wurde schlussendlich auch verworfen.
%reihenfolge 4, 100, 5, 6, 104

Der PC Wert hatte auch noch zu Problemen geführt, da er ursprünglich ein normales Register war.
Das beschreiben von Registern gleichzeitig (Pc Register und Ziel-Register des Befehls) führte zu Fehlern.
Der PC ist jetzt aus der Registerbank ausgelagert.
Das verhinderte die undefinierten Werte in den zwei Register(Banken).

Die finale Implementationm hat keine next sequence PC Werte mehr, sondern nur noch einen PC Register außerhalb der Pipeline.
Dies ist auch getrennt von der Registerbank.
Im write back wird dieser immer um 1 erhöht, sofern nicht gesprungen wird.
Wird im memory-access ein Sprung festgestellt, wird ein Will-Jump Signal vom memory access zum wirte back auf 1 gestellt.
Dies veranlasst die writeback stage nicht den PC-Wert um 1 zu erhöhen, sondern den Target Wert als neuen PC-Wert zu setzen.
Die gesamte PC-Logik ist somit im write back.
Durch die Anpassungen ist die gesamte fetch stage obsolet geworden.
Die  Instruction Decode stage ließt direkt den Input vom instruction memory.

% Angleichen an vorherige Kapitel
% Fetch stage gibt es nicht mehr
% "da es einige Schwierigkeiten gab: Die erste Implementation war fehlerhaft." vllt a bisserl schöner umschreiben
% Die next-seq pc problematik kommt noch nicht sauber durch
% Immer hat was weiteres zu problemen geführt (sehr abgehackt)
% "Angenommen ein Jump-befehl" fehlende überleitungen (sehr abgehackt)
% "Das Ganze ist offensichtlich fehlerhaft" unschön (und der Fehler kommt nur zu 90% raus)
% "Das beschreiben von Registern gleichzeitig führte zu Fehlern." - Immer führte was zu fehlern. Was für fehler. (Doppelung zwei sätze später)

(freddy)

\section{Decoder}

Der Decoder ist als eine eigene VHDL-Entity definiert.
Seine Aufgabe es ist den 32-Bit-Code von dem Instructionmemory zu interpretieren, dessen Information zu filtern und diese den entsprechenden Outputs zuzuweisen.
Wie im Kapitel des Befehlssatzes beschrieben, werden die 32-Bit-Befehle im Decoder in die einzelnen Informationsbausteine zerlegt.
% Verweis auf Kapitel
% Einheitliche Bezeichnung für Instructionmemory

\begin{figure}[h]
\centering
% \includegraphics{Figure 3.2.1}
\caption{Bild}
\end{figure}

In der ersten Version des Decoders verglich der Decoder den ermittelten \enquote{Opcode} mit dem des Befehlssatzes.
Dies wurde durch eine \enquote{Fallunterscheidung}(cases) realisiert.
Nachdem eine Übereinstimmung gefunden wurde, wurde das Immediate-Bit geprüft.
In Abhängigkeit des \enquote{Opcodes} und des Immediate-bits wurden dann die weiteren Informationen des 32Bit-Codes vom Decoder an die entsprechenden Outputs weitergeleitet.
Dies sind:

\begin{description}
  \item [Alu-Opcode] Der Alu-Opcode ist ein 5-Bit großer Befehlssatz für die Alu.
  Er wurde eingeführt, um gleiche Verhaltensweisen der Alu, bei unterschiedlichen "Opcodes" zusammenzufassen.
  \item [Register] Hierbei handelt es sich um Register, die entweder gelesen oder beschrieben werden sollen.
  \item [Immediate-wert] Der Immediate-Wert ist eine 16-Bit lange Zahl, die als Adresse oder Inhalt interpretiert werden kann.
  \item [Write-Enable] Vergleichbar mit einer Flag, ist das \enquote{Write-Enable} ein 1-Bit großes Signal, das ausschließlich dafür benötigt wird, um zu bestimmen, ob ins Register geschrieben werden soll.
\end{description}

In der finalen Version des Decoders wurde die Arbeitsweise des anfänglichen Decoders effizienter gestaltet.
Die ganzen \enquote{Fallunterscheidungen} der einzelnen \enquote{Opcodes} wurden durch eine Unterscheidung ihres \enquote{Layouts} ersetzt.
Dadurch werden nun nicht alle 5 Bits des \enquote{Opcodes} überprüft, sondern nur die ersten 2 Bits.
Ähnlich wie bei einem KV-Diagramm, könnte man die restlichen Bits als \enquote{don't care} behandeln.
Diese 2 Bits sind wie im Kapitel \ref{ch:Befehlssatz} beschrieben, ausschlaggebend für das Layout des 32-Bit-Codes.
In Abhängigkeit des \enquote{Layouts} und des Immediate-Bits werden immer bestimmte Bits des 32-Bit-Codes an die Outputs zugewiesen.

\begin{figure}[h]
\centering
% \includegraphics{Figure 3.2.1}
\caption{Bild}
\end{figure}

*Ausnahme ist der Move-Befehl, da dieser aus inhaltlicher Logik anders zu behandeln ist.

Je nach Layout sind somit andere Bits des 32-Bit-Codes relevant bzw. andere irrelevant.
Analog zum Opcode ermöglicht dies, dass nicht genau geprüft werde muss, was sich in den irrelevanten Teilen des Codes befindet.
Dadurch wird die Logik im Decoder minimiert. 
Ein weiterer Vorteil dieser Entscheidung ist, dass weitere Befehle so einfacher zu ergänzen sind, da sie nur der Grammatik des dazugehörigem Layout entsprechen müssen um deren Inhalt zu dekodieren.  


(paddy)

\section{ALU}

Die ALU ist für die logischen und arithmetischen Operationen verantwortlich.
Sie erhält ihren Opcode vom Decoder.
Es gibt zwei Operanden als Input und ein Input Flag - das Carry Bit.
Herzstück der ALU ist eine große Switch Anweisung, die abhängig vom Opcode die zwei Operanden mit einander verrechnet.
Die ALU unterstützt insgesamt 14 Operationen.
Die Overflow, CarryOut und Compare Flags, werden konstant berechnet.
Ursprünglich wurde das Flag-Register jeden Taktzyklus geschrieben.
Die ALU \enquote{änderte} Flags nur, sofern es nötig war.
Dies führte zum gleichen Problem, wie auch beim PC Handling.
Nachfolgende Befehle erhielten noch die alten Flagwerte. 
%Die letzten zwei als einen Satz?
Da bei jedem Takt ins Flagregister geschrieben wurde, überschrieb der nachfolgende Befehl die gesetzten Flags des vorherigen.
Die Lösung bestand darin, die Carry- und Overflowflags nur bei Addition und Subtraktion zu schreiben.
Das Compare-flag wurde nur entsprechend gesetzt, sofern ein Compare-befehl in write-back war.
Das Overflow-Flag ist nicht implementiert.
Es lag bisher nicht im Fokus.
Die Zielberechnung von Fibonacci funktioniert auch ohne.
%Zeitformen überprüfen

(freddy)

\chapter{Software}
Im folgenden stellen wir die Arbeit des Softwareteams vor.
Wir beginnen mit einem kurzen Einblick in unseren Arbeitsablauf, danach stellen wir die verschiedenen Schritte der Softwarentwicklung vor um abschließend einen Überblick über die Funktionalität des Compilers am Ende des Projekts zu liefern.

\section{Entwicklungsprozess}
Das Vorgehen des Softwareteams bestand aus mehreren Schritten.
Generell haben wir uns einmal in der Woche getroffen um den aktuellen Stand unserer Arbeit zu besprechen.
Je nachdem was zu tun war, haben wir entweder zusammen an einer Aufgabe gearbeitet, oder aber die anstehenden Aufgaben verteilt, so dass jeder in Ruhe und zu einem ihm passenden Zeitpunkt daran arbeiten konnte.
Zunächst mussten wir uns entscheiden mit welcher Sprache und welchen weiteren Tools unseren Compiler implementieren wollten.
Bei der Recherche nach guten Tools zur Spracherstellung stießen wir auf ANTLR.
Da uns die Syntax der Grammatiken (ähnlich zur Backhus-Naur Form) gefiel und wir beide mit Java vertraut sind, haben wir uns für das Tool entschieden.
Der zweite Schritt unserer Arbeit bestand darin sich mit ANTLR vertraut zu machen.
Dieser Schritt nahm etwas mehr Zeit in Anspruch als erwartet, da zunächst einige technische Probleme aus der Welt geräumt werden mussten, die bei der Einrichtung des neuen Frameworks auftraten.
Nachdem die Technik schließlich stand und wir die Schnittstelle von ANTLR verstanden hatten war die Implementation des Compilers relativ unproblematisch. Dieser widmen wir uns im folgenden.
% Backus Naur Satz
% Zu oft das Wort wir/uns/etc

(lennart)

\section{Anforderungsanalyse}
Zu Beginn des Softwareentwicklungsprojektes bestand die erste Herausforderung darin, eine auf das Problem zugeschnittene Anforderungsbeschreibung zu erstellen.
Die grundsätzlichen Anforderungen konnten dabei prinzipiell in die funktionalen und die technischen Anforderungen unterteilt werden. 

\subsection{Funktionale Anforderungen}
Die funktionalen Anforderungen beschreiben, über welche Funktionen die Software am Ende des Entwicklungsprozesses verfügen muss.
Um eine realistisch zu bewältigende Menge an Funktionen auswählen zu können, war eine  kritische Selektion dieser notwendig.
So gab es z.B. zu Beginn die Idee eine diskrete Simulationsumgebung zu erstellen. Allerdings wurde diese Möglichkeit wieder verworfen, da unklar war, wie lange die Implementation dieses Features gedauert hätte und wie lange die Entwicklung des Compilers selbst dauert.
Wir entschieden uns also zunächst dafür, uns ausschließlich auf den Compiler (Assemblercode zu Binärcode) zu fokussieren.
Die dafür notwendigen funktionalen Anforderungen konnten relativ schnell ermittelt werden.

\subsubsection{Primäre Funktionen}
Zum einen bestand das primäre Ziel darin, eine beliebige Textdatei mit Assemblercode automatisch einlesen zu können, aus dem eine neue Textdatei - bestehend aus Binärcode - generiert werden sollte.
Zum anderen musste es eine geeignete Möglichkeit geben syntaktische Fehler innerhalb des Assemblercodes zu erkennen und auszugeben.

\subsubsection{Sekundäre Funktionen}
Neben den primären Funktionen sollte es die Möglichkeit geben innerhalb der Software Makros zu erstellen, welche Operationen ermöglichen, die nicht im Instruction Set explizit definiert sind.
Beispielsweise besitzt unser Instruction Set keinen Multiplikationsbefehl (\texttt{MUL}).
Dennoch kann der \texttt{MUL}-Befehl im Assemblercode benutzt werden, da er intern durch die russische Bauernmultiplikation ersetzt wird.
Zusätzlich dazu war unklar, inwieweit das Hardwareentwicklungsteam auf Hazards im Rahmen des Pipelining reagieren könnte.
Aus diesem Grund musste ein softwaretechnischer Lösung  gefunden werden, welche auf jedenfall funktioniert.
Zu Beginn wurde lediglich festgelegt, dass wir nach jedem Befehl eine notwendige Anzahl NOOP-Befehle einfügen.
Da dieses Prinzip allerdings völlig ungeeignet ist - wofür eine Pipeline benutzen, wenn sie obsolet gemacht wird? - entschieden wir uns dazu bestimmte Abhängigkeiten von Beginn an mit ein zu beziehen.
Z.B. befüllen der Pipeline vor einem Jump-Befehl mit ausreichend vielen NO-Ops oder das Erkennen der Abhängigkeiten von genutzten Registern.

\subsection{Technische Anforderungen}
Nach Fertigstellung der funktionalen Anforderungsanalyse gingen wir dazu über, eine Liste an technischen Anforderungen des Systems zu entwerfen.

\subsubsection{Änderbarkeit}
Aufgrund des (vorläufigen) Mangels an Fachkenntnis war es von sehr großer Bedeutung das System so zu gestalten, dass Änderungen an der Struktur des Assemblercodes oder an den funktionalen Anforderungen ohne großen Aufwand gemacht werden konnten.

\subsubsection{Erweiterbarkeit}
Da zu Beginn des Entwicklungsprozesses nur schwer abzuschätzen war, wie lange wir für die Implementation von bestimmten Funktionen brauchen, war es notwendig das System so zu gestalten, dass eine einfache Erweiterbarkeit von Funktionalitäten gegeben ist.
Wir entschieden uns daher ein geeignetes Framework zu suchen, welches dieses Qualitätsmerkmal ausreichend erfüllt. 

\subsubsection{Korrektheit}
In Folge der Tatsache, dass Binärcode nur äußerst schwer zu Debuggen ist, war eine Hauptanforderung ein hohes Maß an Korrektheit der Übersetzung.
Aufgrund der anfänglich ungünstigen Designentscheidung keinen diskreten Simulator zum Testen zu entwickeln, mussten wir warten, bis das Hardwareentwicklungsteam einen ausreichend funktionierenden Simulator fertiggestellt hatte.
Aus diesem Grund dauerte das Debugging wesentlich länger als notwendig.

\subsubsection{Vernachlässigte Qualitätsmerkmale}
Standardmäßig gibt es im Laufe einer jeden Softwareentwicklung Entscheidungen zu signifikanten Qualitätsmerkmalen zu fällen.
So entschieden wir uns bewusst dafür, dass die Effizienz des Programms eine sehr untergeordnete Rolle spielen sollte, da es praktisch ausgeschlossen war, dass wir große Mengen an Quellcode in sehr kurzer Zeit übersetzen müssen.

(leonard)

\section{ANTLR}
%https://www.antlr.org/
In der Vorbereitung für die Entwicklung des Compilers haben wir verschiedene Möglichkeiten abgewogen, wie die von uns gesteckten Ziele am besten zu erreichen sind.
Die simpelste Möglichkeit wäre es gewesen den Quellcode direkt mit einem großen Switch Statement zu parsen und die einzelnen Befehle dann zu übersetzen.
Da dies jedoch schnell relativ unübersichtlich zu werden schien und im Widerspruch zu den gesetzten funktionalen Anforderungen gestanden hätte, haben wir Ausschau nach möglichen Tools gehalten, mit denen wir unsere Ziele besser erreichen konnten.
Dabei sind wir auf ANTLR gestoßen.
ANTLR (ANother Tool for Language Recognition) ist ein Parser Generator zum Lesen und Verarbeiten von strukturierten Textdateien auf der Basis von Grammatiken, der unter anderem verwendet werden kann, um eigene Programmiersprachen zu entwickeln.
% cite ANTLR
Um einen Compiler mit ANTLR zu erstellen, benötigt man zunächst eine Grammatik, in der die formalen Regeln der Sprache beschrieben werden.
Die Grammatik besteht aus Parser- und Lexer-Regeln.
Dabei stehen die Parserregeln für die Struktur der Sprache (Nonterminale) und die Lexerregeln für die tatsächlichen Zeichen/Wörter (Terminale), die die Nonterminale ersetzen können.
Die Grammatik kann mit Hilfe von ANTLR zu Java Klassen compiliert werden.
ANTLR liefert dabei einen Lexer und einen Parser mit deren Hilfe ein Parsetree generiert werden kann.
Dazu wird einfach eine Datei mit dem Quellcode eingelesen und mithilfe von Lexer und Parser verarbeitet.
Der resultierende Parsetree kann mit Hilfe von Visitors durchlaufen werden,
welche dann die eigentliche Übersetzungsarbeit leisten.

(lennart \& leonard)


\section{Compiler Implementation}

\subsection{Grammatik}
ANTLR nutzt zum Parsen eine kontextfreie Grammatik der Form: $G = (V, T, P, S)$.
Hierbei entspricht V der endlichen Menge der Variablen (Menge der Ableitungsregeln, bzw. Parser-Regeln), $T$ der Menge der Terminalen (Tokens, bzw. Lexer-Regeln), $P$ den Produktionsregeln (Parser-Regeln bzw. Ableitungsregeln) und $S$ der Startregel.
Basierend auf der Grammatik existiert also eine Sprache $L(G)$. Für jeden von uns vorgesehenen Assemblerbefehl $A$ gilt also: $A \in L(G)$. 

(leonard)

\subsubsection{Lexer - Lexikalischer Scanner}
Der Lexer stellt die unterste Ebene einer Grammatik dar.
Jede Lexer-Regel definiert dabei genau einen Token.
Ziel des Lexers ist es nun für jede mögliche Eingabe zu erkennen, um welches Token es sich handelt.
Hierbei gilt zu beachten, dass ein Token nicht zwangsläufig exakt definiert werden muss, da die Nutzung von regulären Ausdrücken möglich ist.
%listng austauschen, kommaenatre weg, in eine fig. rein 

\begin{figure}[h]
    \begin{lstlisting}
        MOV: 'MOV';
        BINARY: '0b' ([0-1])+;
    \end{lstlisting}
\end{figure}

Zu Beginn des Prozesses werden so zunächst sämtliche Eingaben in Tokens umgewandelt, welche dann von den Parser-Regeln in einen Syntax-Baum überführt werden.

(leonard)

\subsubsection{Parser}
Die Parser-Regeln definieren den Ableitungsbaum der formalen Grammatik.
Dabei entspricht jede Verzweigung einer Parser-Regel, während jeder Blattknoten einem Token entspricht.

\begin{figure}[h]
\centering
% \includegraphics{Figure 3.2.1}
\caption{Syntaxbaum des Befehls: \texttt{MOV, r10, 10;}}
\end{figure}

Eine Parser-Regel hat die Form
%listng austauschen, kommaenatre weg, in eine fig. rein 
\begin{lstlisting}
start: start command | command;
\end{lstlisting}
wobei die Regel entweder direkt ein Token nutzt oder auf eine weitere Regel verweist.
Anhand der Ableitungsregeln kann also eine Struktur erstellt werden, auf welche nun spezifisch reagiert werden kann.
So ist es innerhalb des Programmes nun möglich auf jeden Knoten des Baumes, sowie seine Eltern- und Kindknoten zuzugreifen.

(leonard)

\subsection{Die Visitor Klassen}
Da unser Compiler mehrere Aufgaben erfüllen soll, die nur sequentiell erledigt werden können, wird dieser Ablauf insgesamt drei mal durchlaufen.
Eine Klasse die ein Dokument durchläuft, und diese mit Hilfe von ANTLR verarbeitet nennt sich Visitor.
Bei jedem Durchlauf wird ein anderer Arbeitsschritt erledigt.
Die drei Schritte sind das Ersetzen von Makros durch ihre jeweilige Implementation, das Einfügen von NOOPS zur Vermeidung von Hazards und die eigentliche Übersetzung.

\subsubsection{Makros}
Makros wurden von uns mit eigenen Lexer- und Parser-Rules innerhalb der Grammatik implementiert.
Dies ermöglicht es uns die so definierten Makros wie normale Befehle im Quellcode zu verwenden.
Der Compiler kümmert sich dann darum die Mnemoniks durch entsprechende Funktionen zu ersetzen.
% erläutern: mnemoniks (vllt in ner fussnote)
Zum aktuellen Zeitpunkt haben wir die russische Bauernmultiplikation für positive Zahlen (MUL) und ein simples binäres Invertieren (NOT) durch Makros verwirklicht.
Es lassen sich leicht zusätzliche Makros hinzufügen, indem diese in der Grammatik definiert  und entsprechende Implementation im Compiler verwirklicht werden.
In der Grammatik müssen die entsprechenden Regeln eingetragen werden. Im Makro Visitor muss der entsprechende Quellcode hinterlegt werden, mit dem der Makro Befehl ersetzt wird.
Bei der Verwendung von Makros muss beachtet werden, dass diese nicht immer \enquote{in place} implementiert werden können.
Es werden für ein Makro also möglicher Weise mehr Register gebraucht als die 3 Register die durch einen 3-Op Befehl zur Verfügung stehen.
Daher ist es empfehlenswert, zu dokumentieren, welche Register von den jeweiligen Makros verwendet werden, um Inkonsistenzen zu vermeiden.
Das Vorgehen des Makro-Visitors besteht also darin den übergebenen Quellcode größtenteils unverändert zurück zu geben und nur die Stellen, an denen ein Makro entdeckt wird, zu ersetzen.

(lennart)

\subsubsection{Jumplabels und NOOPS}
Im zweiten Übersetzungsschritt werden die jump-Labels zu absoluten Zeilenangaben übersetzt und \texttt{NOOPS} eingefügt.
Die Sprungadressen werden ermittelt, indem der Compiler mitzählt, wie viele Befehle bereits gesehen wurden.
%"gesehen werden" gut formuliert
Da Sprünge im Instruktionsspeicher über einen Befehlsindex implementiert sind, reicht dieser aus um Sprünge mit Immediate zu realisieren.
Die Indizes werden zusammen mit den Labels gespeichert, sodass die Labels im Übersetzungsschritt durch die Immediate Werte ersetzt werden können.
Eine weitere Aufgabe innerhalb dieses Schrittes ist das Einfügen von \texttt{NOOPS}, um Hazards zu vermeiden.
Um dies zu bewerkstelligen, merkt sich der Compiler für jedes Register die Anzahl der notwendigen NOOPS, die eingefügt werde müssten, falls das Register im aktuellen Befehl vorkommt.
Ist der Wert 0 wird für das jeweilige Register der Wert auf 4 gesetzt, was der Anzahl der Pipelinestufen entspricht.
Falls der Wert nicht 0 ist, werden entsprechend viele führende \texttt{NOOPS} eingefügt und danach der Wert auf 4 gesetzt. 
%was heißt entsprechend viele ? 
Nach jeder Operation werden die Zähler um eins dekrementiert bis sieh wieder 0 sind.
Außerdem werden generell nach jedem Sprung (\texttt{JMP}, \texttt{B}) 3 \texttt{NOOPS} eingefügt, da wir für den Prozessor keinen Flush implementiert haben. Es werden nur 3 und nicht 4 \texttt{NOOPS} gebraucht, da 
% Warum nur 3 nicht 4??
Auf diese Weise wird vermieden, dass ungewollte Befehle in die Pipeline geladen werden.

(lennart)

\subsubsection{Übersetzung}
Im letzten Schritt wird der auf diese Weise modifizierte Quellcode in den Maschinencode übersetzt.
Die einzelnen Befehle werden je nach Befehlstyp (NOOP, TWOOP, THREEOP, Jump) unterschiedlich behandelt.
Die Opcodes stehen in einer Hashmap zusammen mit den Mnemoniks für die einzelnen Befehle.
%bild bei befehlswörtern?
Ist der letzte Operand ein Immediate Wert wird das Immediate-Bit wird entsprechend gesetzt.
Die Immediates werden aus dem angegebenen Zahlensystem (binär, hexadezimal, dezimal) zu einer Binärzahl übersetzt.
Alle Operanden werden je nach Befehlsstruktur mit einem entsprechenden 0 Padding versehen. Um die Länge und Struktur des Befehlswort zu erhalten.
Anschließend wird das Befehlswort zusammengesetzt und zusammen mit einer Befehlsnummer am Anfang zurückgegeben.

(lennart)

\chapter{Ergebnis}

\subsubsection{Ergebnis - Softwareentwicklung}
Eine der weitreichendsten Entscheidungen war die Wahl des genutzten Frameworks.
Zu Beginn des Softwareentwicklungsprozesses mussten wir zunächst einige Zeit in diese Entscheidung investieren, da es (neben ANTLR) viele verschiedene Parser-Generatoren mit sehr unterschiedlichen Ansätzen und damit verbundenen Vor- und Nachteilen gibt.
Es kostete uns einige Zeit hierbei, den für uns richtigen Auszuwählen.
Als weiterer aufwändiger Schritt während der Entwicklung stellte sich das Erlernen und die korrekte Anwendung von ANTLR heraus.
ANTLR bietet ein äußerst vielfältiges Spektrum an nutzbaren Funktionen und Möglichkeiten, was sowohl die Grammatik als auch die Implementation angeht.
Ein schwierige Teil hierbei war nun herauszufinden, welche Funktionen tatsächlich gebraucht würden und welche vernachlässigbar waren.
%absatz
Abschließend lässt sich sagen, dass die release Version der Software alle in Kapitel 4.1
%verlinkung zu Chapter 4.1
genannten funktionalen und technischen Anforderungen besitzt.
Dies betrifft sowohl die Bedienung  der Software als auch eine potenzieller Weiterentwicklung bzw. das Hinzufügen von neuen Features.

% TODO

(leonard)

\chapter{Konklusion und Ausblick - In Bearbeitung}
Zum jetzigen Stand der Entwicklung ist der Prozessor in der Lage generische Programme laufen zu lassen.
Dies umfasst u.A. die Berechnung der Fibonacci-Zahlen sowie die Berechnung der Fakultät.
Es existiert ein Compiler der diese, in unserem Assembler geschriebenen Programme, in Maschinencode umwandelt.
Hierbei werden Hazards vermieden.
Der Compiler fügt hierzu an den entsprechenden Stellen NOOPS ein.
Die Ausgabe des Compilers ist eine \texttt{.dat} Datei.
Diese dient als ROM.
Simulieren wir nun mit gdhl den Prozessor, führt dieser das Programm im ROM aus.
In Abbildung XX ist zu sehen, dass nach 400? Zyklen im Register 10? die 10. Fibonacci Zahl steht.
% TODO: fill the blanks

Die Zusammenarbeit des Teams verlief zumeist reibungslos.
Das Hardwareteam tat sich aber deutlich schwerer mit der Aufgabe den Prozessor zu designen.
Dies hatte zwei Gründe.
Zum einen hatte die Gruppe mehr Mitglieder, dies sorgte für mehr Koordinierungsaufwand.
Zum Anderen erwies es sich als äußerst komplex sich mit der Thematik VHDL auseinanderzusetzen und ein umfassendes Verständnis zu erlangen.
So war es notwendig einige Komponenten des Prozessors vollständig neu zu schreiben.
Das Softwareteam hingegen musste \enquote{nur} mit Java und ANTLR einen Text parsen und in Binärcode umwandeln. 
Leider haben sich die beiden Gruppen nicht früh genug getroffen.
So wurden viele Fehler erst spät gefunden und Missverständnisse spät ausgeräumt.
Beispielsweise gab es ein Missverständnis wie viele NOOPS genau eingefügt werden müssen, um Hazards zu vermeiden.
Da beide Gruppen ihre Arbeit nahezu fertig gestellt hatten, waren Änderungen an der Code-Basis unnötig aufwendig.
Auch wäre ein früher Prototyp des Prozessors und Compilers hilfreich gewesen um schon erste Tests unternehmen zu können.
Es hätte helfen können, sich Zwischenziele abzustecken.
Generell kann man sagen hätten wir mehr Kommunizieren sollen.

% Was würden wir anders machen (Inhaltlich)

Der Prozessor befindet sich in einem annähernd fertigen Zustand.
Es fehlen noch ein OP-Code und die (richtige) Implementation des Overflow-Flags sowie des Link-Registers.
All dies ist aber für die Erfüllung unseres selbstgestecken Ziels nicht erforderlich: Fibonacci-Zahlen zu berechnen.
Zugegebenermaßen nicht das höchste aller Ziele aber es involviert alle Kern-Komponenten, die wir einer CPU zuschrieben.
% TODO
In den Entwurf des Prozessors sind weder Überlegungen der Effizienz noch Sparsamkeit eingeflossen.
So ist die Implementation des \texttt{COMPGT} zB. sehr simpel in VHDL zu formulieren.
In der Synthese wird sich daraus wohl eine \enquote{ALU-artige} Struktur ergeben.
Aktuell setzen wir auch Initialwerte innerhalb von VHDL für einige Register um \enquote{undefined} aus dem Weg zu gehen.
Dies lässt sich nicht synthetisieren.
Hier wäre es notwendig eine Alternative zu finden.
Auch haben wir keinerlei Input/Output in den Prozessor eingebaut.
ROM und RAM stellen zur Zeit die einzige Schnittstelle dar.

Zum fetch wegfall: vllt brauchen wir die fetch stage ja doch, wenn speicher nicht so schnell ist, wie in der simulation.
Das müsste man dann testen, bis zu welchem clock speed eine 4 stage cpu und/oder eine 5 stage cpu gehen würde.
% TODO

unit tests, da sich Korrektheit eh nicht formal beweisen lässt, sollte zumindest mit tests eine hinreichende Korrektheit erreicht werden.
% TODO

für vhdl vllt auch gut (-> cocotb)
% TODO

haben uns zu sehr am sketch gehalten (haben lange gebraucht zu raffen, wie man das eig. abstrahiert/einteilt). zu sehr auf das Schaubild fokussiert.
% TODO

% Was könnten wir noch machen (Ausblick)

(hardware:) Bessere VHDL debugging tools (es war schwer zu sehen, was abgeht).
% wegen corona und vnc uni rechner haben wir ghdl + gtkwave benutzt. die tools sind nicht die besten. es war teils sehr aufwendig insights zu bekommen.
% TODO

Abseits dieser Short-comings haben wir noch einige Ideen wie der Prozessor noch weiter zu entwickeln wäre:
Hier wäre zuerst ein dedizierter \texttt{HLT} Befehl zu nennen.
Zur Zeit lassen wir die Simulation nur bis zu einem Punkt laufen und ignorieren alle nachfolgenden Werte.
Würden wir die CPU synthetisieren wäre es wünschenswert den Prozessor halten zu lassen.

\textit{Pipeline Flushing} wäre ein weiteres Feature über das wir uns einige Gedanken gemacht haben.
Springt der Prozessor von einer Instruktion zu einer anderen müssen alle schon in der Pipeline geladenen Befehle als \enquote{invalid} markiert werden.
Zur Zeit wird dies in Software durch den Compiler gelößt, welcher erkennt, dass ein Sprung möglich wäre und entsprechend viele NOOPS einführt.
Zumindest bei Branch-Befehlen ist dies nicht gerade effizient, da egal ob gesprungen wird, NOOPS in die Pipeline geladen werden.
Hier wäre es denkbar einfach eine Datenleitung aus der Writeback stage, wo der PC wert gesetzt wird, zu jeder anderen zu führen.
Diese würde, falls auf 1 gezogen, dafür sorgen, dass jede Stage ein \texttt{NOOP} bit setzt.
Jenes wiederum veranlasst alle nachfolgenden stages dazu keine Schreiboperationen mehr zuzulassen.
Dies würde zum einen die Anzahl der Noops, die vom Compiler eingefügt werden m
%TODO

Ein globales Reset Signal wäre auch noch wünschenswert.
Dieses läge an allen relevanten Registern an - hauptsächlich alles was mit PC Handling zu tun hat - und würde im Falle der Aktivierung diese auf einen Initialwert setzen.
Dies wäre auch eine Lösung für die oben genannte Synthetisierungsproblematik.
Sofern Pipeline-Flushing schon implementiert wäre, sollte es nicht allzu kompliziert sein, dies für einen Reset mit einzubeziehen.

Pipeline-Flushing hilft aber erst einmal nur um NOOPS nach \texttt{JMP} oder \texttt{B} Befehlen zu eliminieren.
Die NOOPS, welche vom Compiler eingefügt werden, um Hazards zu vermeiden, die sich durch Abhängigkeiten zwischen Befehlen ergeben, sind davon nicht berührt.
Hier könnte eine Form von \textit{Forwarding} Abhilfe schaffen.
%citation needed?
Spätere Stages, wie Execute, Memory Access oder Write Back könnten berechnete Werte dem instruction decode bereitstellen.
Somit stünden Ergebnisse früher bereit und könnten früher verwendet werden.
Es müssten nicht mehr entsprechend viele NOOPS eingefügt werden, als das diese in Register geschrieben werden, um Hazards zu vermeiden.

Software: code umsortieren (Instruction reordering)
% Befehle neu sortieren wenn sie das erlauben
% TODO

Mehr makros
% TODO

Thema Floating point: makro - das vllt auch mit hardware support?
Sicherlich gibt's da beispiele bei anderen prozessoren. Mehrere lösungsmöglichkeiten: in software, im compiler, in hardware.
% TODO

LLVM Backend - Königsdisziplin für assembler / compiler.
Damit ließe sich letztlich alles zum prozessor übersetzen.
Man könnte zB. mips adaptieren.
vllt ergäben sich daraus weitere requirements für unseren prozessor (fp).
% TODO

(Leonard \& Max)

\end{document}
